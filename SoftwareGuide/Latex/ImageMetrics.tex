%
%  This file is included by Registration.tex
%
%
%

\index{itk::Image\-To\-Image\-Metricv4}

\begin{floatingfigure}[rlp]{0.5\textwidth}
 \centering
 \includegraphics{ParzenWindowing13.eps}
 \caption[Parzen Windowing in Mutual Information]{
In Parzen windowing, a continuous density function is constructed by
superimposing kernel functions (Gaussian function in this case) centered on the
intensity samples obtained from the image.\label{fig:ParzenWindowing}}
\end{floatingfigure}

In ITK, \doxygen{ImageToImageMetricv4} objects quantitatively measure how well
the transformed moving image fits the fixed image by comparing the gray-scale
intensity of the images. These metrics are very flexible and can work with any
transform or interpolation method and do not require reduction of the
gray-scale images to sparse extracted information such as edges.

The metric component is perhaps the most critical element of the registration
framework. The selection of which metric to use is highly dependent on the
registration problem to be solved. For example, some metrics have a large
capture range while others require initialization close to the optimal
position.  In addition, some metrics are only suitable for comparing images
obtained from the same imaging modality, while others can handle
inter-modality comparisons.
Unfortunately, there are no clear-cut rules as to how to choose a metric.

\index{itk::Image\-To\-Image\-Metricv4!GetValue()}
\index{itk::Image\-To\-Image\-Metricv4!GetDerivatives()}
\index{itk::Image\-To\-Image\-Metricv4!GetValueAndDerivatives()}

The matching Metric class controls most parts of the registration process
since it handles fixed, moving and virtual images as well as fixed and moving
transforms and interpolators.  The method \code{GetValue()} can be used to
evaluate the quantitative criterion at the transform parameters specified in
the argument.  Typically, the metric samples points within a defined region
of the virtual lattice.  For each point, the corresponding fixed and moving
image positions are computed using the fixed initial transform and the moving
transform with the specified parameters. Then, the fixed and moving interpolators
are used to compute the fixed and moving image's intensities at the mapped
positions. Details on this mapping are illustrated in Figures
\ref{fig:ImageOverlapIterator} and \ref{fig:ImageOverlapInterpolator} assuming
that virtual lattice is the same as the fixed image lattice, which is usually the
case in practice.

The metrics also support region-based evaluation. The \code{SetFixedImageMask()} and
\code{SetMovingImageMask()} methods may be used to restrict evaluation of the metric
within a specified region. The masks may be of any type derived from \doxygen{SpatialObject}.

Besides the measure value, gradient-based optimization schemes also require
derivatives of the measure with respect to each transform parameter. The
methods \code{GetDerivatives()} and \code{GetValueAndDerivatives()} can be
used to obtain the gradient information.


The following is the list of metrics currently available in ITKv4 registration framework:
\begin{itemize}
\item Mean squares\\ \doxygen{MeanSquaresImageToImageMetricv4}
\item Correlation \\ \doxygen{CorrelationImageToImageMetricv4}
\item Mutual information by Mattes \\ \doxygen{MattesMutualInformationImageToImageMetricv4}
\item Joint histogram mutual information \\ \doxygen{JointHistogramMutualInformationHistogramImageToImageMetricv4}
\item Demons metric \\ \doxygen{DemonsImageToImageMetricv4}
\item ANTS neighborhood correlation metric \\ \doxygen{ANTSNeighborhoodCorrelationImageToImageMetricv4}
\end{itemize}

Also, in case you are interested in using the legacy ITK registration framework,
the following is the list of metrics currently available in ITKv3:
\begin{itemize}
\item Mean squares\\ \doxygen{MeanSquaresImageToImageMetric}
\item Normalized correlation \\ \doxygen{NormalizedCorrelationImageToImageMetric}
\item Mean reciprocal squared difference \\ \doxygen{MeanReciprocalSquareDifferenceImageToImageMetric}
\item Mutual information by Viola and Wells \\ \doxygen{MutualInformationImageToImageMetric}
\item Mutual information by Mattes \\ \doxygen{MattesMutualInformationImageToImageMetric}
\item Kullback Liebler distance metric by Kullback and Liebler \\ \doxygen{KullbackLeiblerCompareHistogramImageToImageMetric}
\item Normalized mutual information \\ \doxygen{NormalizedMutualInformationHistogramImageToImageMetric}
\item Mean squares histogram \\ \doxygen{MeanSquaresHistogramImageToImageMetric}
\item Correlation coefficient histogram \\ \doxygen{CorrelationCoefficientHistogramImageToImageMetric}
\item Cardinality Match metric \\ \doxygen{MatchCardinalityImageToImageMetric}
\item Kappa Statistics metric\\ \doxygen{KappaStatisticImageToImageMetric}
\item Gradient Difference metric \\ \doxygen{GradientDifferenceImageToImageMetric}
\end{itemize}

In the following sections, we describe the ITKv4 metric types in detail.
You can check ITK descriptions in doxygen for details about ITKv3 metric classes.

For ease of notation, we will refer to the fixed image $f(\bf{X})$
and transformed moving image $(m \circ T(\bf{X}))$ as images $A$ and $B$.

\subsection{Mean Squares Metric}
\label{sec:MeanSquaresMetricv4}
\index{itk::Mean\-Squares\-Image\-To\-Image\-Metricv4}

The \doxygen{MeanSquaresImageToImageMetricv4} computes the mean squared
pixel-wise difference in intensity between image $A$ and $B$ over a user
defined region:

\begin{equation}
MS(A,B) = \frac{1}{N} \sum_{i=1}^N \left( A_i - B_i \right)^2
\end{equation}
\begin{center}
$A_i$ is the i-th pixel of Image A\\
$B_i$ is the i-th pixel of Image B\\
$N$ is the number of pixels considered
\end{center}

The optimal value of the metric is zero. Poor matches between images $A$ and
$B$ result in large values of the metric. This metric is simple to compute and
has a relatively large capture radius.

This metric relies on the assumption that intensity representing the same
homologous point must be the same in both images. Hence, its use is restricted
to images of the same modality. Additionally, any linear changes in the
intensity result in a poor match value.

\subsubsection{Exploring a Metric}
\label{sec:ExploringAMetric}

Getting familiar with the characteristics of the Metric as a cost function is
fundamental in order to find the best way of setting up an optimization process
that will use this metric for solving a registration problem. The following
example illustrates a typical mechanism for studying the characteristics of a
Metric. Although the example is using the Mean Squares metric, the same
methodology can be applied to any of the other metrics available in the
toolkit.

\ifitkFullVersion
\input{MeanSquaresImageMetric1.tex}
\fi


\subsection{Normalized Correlation Metric}
\label{sec:NormalizedCorrelationMetric}
\index{itk::Correlation\-Image\-To\-Image\-Metricv4}

The \doxygen{CorrelationImageToImageMetricv4} computes pixel-wise
cross-correlation and normalizes it by the square root of the autocorrelation
of the images:

\begin{equation}
NC(A,B) = -1 \times \frac{ \sum_{i=1}^N \left( A_i \cdot B_i \right) }
        { \sqrt { \sum_{i=1}^N A_i^2  \cdot \sum_{i=1}^N B_i^2 } }
\end{equation}
\begin{center}
$A_i$ is the i-th pixel of Image A\\
$B_i$ is the i-th pixel of Image B\\
$N$ is the number of pixels considered
\end{center}

Note the $-1$ factor in the metric computation. This factor is used to make the
metric be optimal when its minimum is reached.  The optimal value of the metric
is then minus one. Misalignment between the images results in small measure
values.  The use of this metric is limited to images obtained using the same
imaging modality.  The metric is insensitive to multiplicative factors between
the two images.  This metric produces a cost function with sharp peaks and
well-defined minima.  On the other hand, it has a relatively small capture radius.


\subsection{Mutual Information Metric}
\label{sec:MutualInformationMetric}

The \doxygen{MattesMutualInformationImageToImageMetricv4} computes the mutual
information between image $A$ and image $B$.  Mutual information (MI)
measures how much information one random variable (image intensity in one
image) tells about another random variable (image intensity in the other
image). The major advantage of using MI is that the actual form of the
dependency does not have to be specified.  Therefore, complex mapping between
two images can be modeled.  This flexibility makes MI well suited as a
criterion of multi-modality registration~\cite{Pluim2003}.

Mutual information is defined in terms of entropy. Let
\begin{equation}
H(A) = - \int p_A(a) \log p_A(a)\, da
\end{equation}
be the entropy of random variable $A$, $H(B)$ the entropy of
random variable $B$ and
\begin{equation}
H(A,B) = \int p_{AB}(a,b) \log p_{AB}(a,b)\,da\,db
\end{equation}
be the joint entropy of $A$ and $B$. If $A$ and $B$ are independent, then
\begin{equation}
p_{AB}(a,b) = p_A(a) p_B(b)
\end{equation}
and
\begin{equation}
H(A,B) = H(A) + H(B).
\end{equation}
However, if there is any dependency, then
\begin{equation}
H(A,B)<H(A)+H(B).
\end{equation}
The difference is called Mutual Information : \( I(A,B) \)
\begin{equation}
I(A,B)=H(A)+H(B)-H(A,B)
\end{equation}

\subsubsection{Parzen Windowing}

In a typical registration problem, direct access to the marginal
and joint probability densities is not available and hence the
densities must be estimated from the image data. Parzen windows
(also known as kernel density estimators) can be used for this purpose.
In this scheme, the densities are constructed by taking intensity
samples $S$ from the image and super-positioning kernel functions
$K(\cdot)$ centered on the elements of $S$ as illustrated in
Figure \ref{fig:ParzenWindowing}:

A variety of functions can be used as the smoothing kernel with the
requirement that they are smooth, symmetric, have zero mean and
integrate to one. For example, boxcar, Gaussian and B-spline functions are
suitable candidates.  A smoothing parameter is used to scale the kernel
function.  The larger the smoothing parameter, the wider the kernel function
used and hence the smoother the density estimate. If the parameter is too
large, features such as modes in the density will get smoothed out.  On the
other hand, if the smoothing parameter is too small, the resulting density
may be too noisy. The estimation is given by the following equation.

\begin{equation}
p(a) \approx P^{*}(a) = \frac{1}{N} \sum_{s_j \in S} K\left(a - s_j\right)
\end{equation}

Choosing the optimal smoothing parameter is a difficult research problem and
beyond the scope of this software guide.  Typically, the optimal value of the
smoothing parameter will depend on the data and the number of samples used.

\subsubsection{Mattes et al. Implementation}
The implementation of mutual information metric available in ITKv4 follows
the method specified by Mattes et al. in \cite{Mattes2001} and is implemented
by the \doxygen{MattesMutualInformationImageToImageMetricv4} class.

\index{itk::Mattes\-Mutual\-Information\-Image\-To\-Image\-Metricv4}
In this implementation, only one set of intensity samples is drawn from the
image.  Using this set, the marginal and joint probability density function
(PDF) is evaluated at discrete positions or bins uniformly spread within the
dynamic range of the images. Entropy values are then computed by summing over
the bins.

\index{itk::Mattes\-Mutual\-Information\-Image\-To\-Image\-Metricv4!SetNumberOfHistogramBins()}

The number of spatial samples used is a ratio of the total number of samples
and is set using the \code{SetMetricSamplingPercentage()} method directly from
the registration framework \doxygen{ImageRegistrationMethodv4}. Also, The number
of bins used to compute the entropy values is set in the metric class
via the \code{SetNumberOfHistogramBins()} method.

Since the fixed image PDF does not contribute to the metric derivatives, it
does not need to be smooth. Hence, a zero-order (boxcar) B-spline kernel is
used for computing the PDF. On the other hand, to ensure smoothness, a
third-order B-spline kernel is used to compute the moving image intensity PDF. The
advantage of using a B-spline kernel over a Gaussian kernel is that the
B-spline kernel has a finite support region. This is computationally
attractive, as each intensity sample only affects a small number of bins and
hence does not require a $N \times N$ loop to compute the metric value.

During the PDF calculations, the image intensity values are linearly scaled
to have a minimum of zero and maximum of one. This rescaling means that a
fixed B-spline kernel bandwidth of one can be used to handle image data with
arbitrary magnitude and dynamic range.


\subsection{Normalized Mutual Information Metric}
Given two images, $A$ and $B$, the normalized mutual information may be computed as
\begin{equation}
NMI(A,B) = 1 + \frac{I(A,B)}{H(A,B)} = \frac{H(A) + H(B)}{H(A,B)}
\end{equation}
where the entropy of the images, $H(A)$, $H(B)$, the mutual
information, $I(A,B)$ and the joint entropy $H(A,B)$ are computed as mentioned
in \ref{sec:MutualInformationMetric}. Details of the implementation may be found in
\cite{Hajnal2001}.

\subsection{Demons metric}
\index{itk::Demons\-Image\-To\-Image\-Metricv4}

The implementation of the \doxygen{DemonsImageToImageMetricv4} metric is taken from
\doxygen{DemonsRegistrationFunction}.

The metric derivative can be calculated using image derivatives
either from the fixed or moving images. The default is to use fixed-image
gradients. See ObjectToObjectMetric::SetGradientSource to change
this behavior.

An intensity threshold is used, below which image pixels are considered
equal for the purpose of derivative calculation. The threshold can be
changed by calling \code{SetIntensityDifferenceThreshold}.

Note that this metric supports only moving transforms with local support and
with a number of local parameters that match the moving image dimension.
In particular, it's meant to be used with \doxygen{DisplacementFieldTransform}
and derived classes.


\subsection{ANTS neighborhood correlation metric}
\index{itk::ANTS\-Neighborhood\-Correlation\-Image\-To\-Image\-Metricv4}

The \doxygen{ANTSNeighborhoodCorrelationImageToImageMetricv4} metric computes
normalized cross correlation using a small neighborhood for each voxel between
two images, with speed optimizations for dense registration.

Around each voxel, the neighborhood is defined as a N-Dimensional
rectangle centered at the voxel. The size of the rectangle is 2*radius+1.
Normalized correlation between neighborhoods of the fixed image and the moving
image are averaged over the whole image as the final metric.
A radius less than 2 can be unstable. 2 is the default.

